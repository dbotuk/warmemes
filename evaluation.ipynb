{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13300dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-score in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from bert-score) (2.5.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from bert-score) (2.1.1)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from bert-score) (4.41.1)\n",
      "Requirement already satisfied: numpy in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from bert-score) (1.26.4)\n",
      "Requirement already satisfied: requests in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from bert-score) (4.65.0)\n",
      "Requirement already satisfied: matplotlib in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from bert-score) (3.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from bert-score) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: filelock in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from requests->bert-score) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from requests->bert-score) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from requests->bert-score) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from requests->bert-score) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf083632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9804f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'base_paligemma_uamemes_predicted_answers (2).json'\n",
    "\n",
    "with open(file_name, 'r') as file:\n",
    "    results = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1887660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = list(map(lambda entry: entry['ground-truth-answer'], results))\n",
    "predicted = list(map(lambda entry: entry['answer'], results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75f5f29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377e729b61374295b10026391cf7c154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0baea07e2a346d2be07e320e5b57080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 3.48 seconds, 83.59 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "precisions, recalls, f1_scores = score(predicted, ground_truth, lang=\"uk\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37101766",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = list(map(lambda score: score.item(), precisions))\n",
    "recalls = list(map(lambda score: score.item(), recalls))\n",
    "f1_scores = list(map(lambda score: score.item(), f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3bd61ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (precision, recall, f1) in enumerate(zip(precisions, recalls, f1_scores)):\n",
    "    metric = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    results[i]['metric'] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a110ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.6300064021164609\n",
      "Average Recall: 0.6444388361730936\n",
      "Average F1: 0.6357451733649802\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Precision: {np.mean(precisions)}\")\n",
    "print(f\"Average Recall: {np.mean(recalls)}\")\n",
    "print(f\"Average F1: {np.mean(f1_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffc027d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'question': 'Про яку подію йдеться у цьому мемі?', 'ground-truth-answer': 'Вибух на Кримському мосту', 'answer': 'Вибух на мосту Арапучи.', 'metric': {'precision': 0.8338742256164551, 'recall': 0.8542201519012451, 'f1': 0.8439245820045471}},\n",
       "       {'question': 'Про які країни чи міста йдеться в цьому мемі?', 'ground-truth-answer': 'Москва', 'answer': 'Росія та Москва.', 'metric': {'precision': 0.7679848670959473, 'recall': 0.8300695419311523, 'f1': 0.7978212237358093}},\n",
       "       {'question': 'Про яку подію йдеться у цьому мемі?', 'ground-truth-answer': 'Відступ російської армії з Харківщини', 'answer': 'Винищування російських військ у Вікторії.', 'metric': {'precision': 0.7873832583427429, 'recall': 0.8038998246192932, 'f1': 0.795555830001831}},\n",
       "       {'question': 'Про яку подію йдеться у цьому мемі?', 'ground-truth-answer': 'Виявилося, що російські військові копали окопи в Чорнобильській зоні', 'answer': 'Російські військові входить у Чернобиль.', 'metric': {'precision': 0.8351117372512817, 'recall': 0.7472822666168213, 'f1': 0.7887595891952515}},\n",
       "       {'question': 'Про яку подію йдеться у цьому мемі?', 'ground-truth-answer': 'Російська армія показала свою слабкість', 'answer': 'Російська армія виступає на політичних змаганнях.', 'metric': {'precision': 0.7688870429992676, 'recall': 0.7885175347328186, 'f1': 0.7785786390304565}},\n",
       "       {'question': 'Про яку подію йдеться у цьому мемі?', 'ground-truth-answer': 'Відступ російської армії з Харківщини', 'answer': 'Напад російської армії на Україну 24 березня 2022 року.', 'metric': {'precision': 0.7336206436157227, 'recall': 0.8116035461425781, 'f1': 0.7706443071365356}},\n",
       "       {'question': 'Про які країни чи міста йдеться в цьому мемі?', 'ground-truth-answer': 'Чорнобиль', 'answer': 'Цернобиль, Україна.', 'metric': {'precision': 0.7480756640434265, 'recall': 0.7909564971923828, 'f1': 0.7689186930656433}},\n",
       "       {'question': 'Про яку подію йдеться у цьому мемі?', 'ground-truth-answer': 'Українські атаки на Росію посилюються', 'answer': 'Російська агресія на Україну.', 'metric': {'precision': 0.759162425994873, 'recall': 0.7474655508995056, 'f1': 0.7532685995101929}},\n",
       "       {'question': 'Про яку подію йдеться у цьому мемі?', 'ground-truth-answer': 'Тривають українські атаки на російські нафтопереробні заводи', 'answer': 'Напад російських дронів на українські аеропорти.', 'metric': {'precision': 0.7688186168670654, 'recall': 0.7374030351638794, 'f1': 0.7527831792831421}},\n",
       "       {'question': 'Про який вид зброї йдеться у цьому мемі?', 'ground-truth-answer': 'Кинджал', 'answer': 'Місіс Кінзхіль.', 'metric': {'precision': 0.7340877056121826, 'recall': 0.7628554105758667, 'f1': 0.7481951713562012}}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_indices = np.argsort(f1_scores)[-10:][::-1]\n",
    "np.array(results)[top_10_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9718a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'question': 'Про які країни чи міста йдеться в цьому мемі?', 'ground-truth-answer': 'Київська обл;Київ', 'answer': 'Кіт на зображенні зображений у кількох країнах та містах, включаючи Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну, Україну', 'metric': {'precision': 0.44431763887405396, 'recall': 0.5617101192474365, 'f1': 0.4961647093296051}},\n",
       "       {'question': 'Про яку подію йдеться у цьому мемі?', 'ground-truth-answer': 'У Москві пройшов традиційний парад Перемоги. Був лише один танк.', 'answer': 'Парад.', 'metric': {'precision': 0.5168226957321167, 'recall': 0.48101097345352173, 'f1': 0.49827420711517334}},\n",
       "       {'question': 'Про які країни чи міста йдеться в цьому мемі?', 'ground-truth-answer': 'Німеччина', 'answer': 'УКРАЇНА.', 'metric': {'precision': 0.47847452759742737, 'recall': 0.5567196011543274, 'f1': 0.5146399736404419}},\n",
       "       {'question': 'Про які країни чи міста йдеться в цьому мемі?', 'ground-truth-answer': 'Ізраїль', 'answer': 'Мемі зображує пожежу в Україні, тому країна чи міста, йдеться в цьому мемі, – Україна та пожежа в Україні.', 'metric': {'precision': 0.5197140574455261, 'recall': 0.5213264226913452, 'f1': 0.5205190181732178}},\n",
       "       {'question': 'Про які країни чи міста йдеться в цьому мемі?', 'ground-truth-answer': 'Київська обл;Київ;Бородянка', 'answer': 'УКРАЇНА.', 'metric': {'precision': 0.5205258131027222, 'recall': 0.5336946249008179, 'f1': 0.52702796459198}},\n",
       "       {'question': 'Про які країни чи міста йдеться в цьому мемі?', 'ground-truth-answer': 'Каховка', 'answer': 'Мемі зображує військові, які грають у гру з підписом «Україна в небезпеці. Наша вдача вдається. Наша не вдача. Наша намагається. Наша намагається. Наша намагається. Наша намагається. Наша намагається. Наша намагається. Наша намагається. Наша намагається. Наша намагається. Наша', 'metric': {'precision': 0.4596293270587921, 'recall': 0.6229256391525269, 'f1': 0.5289614200592041}},\n",
       "       {'question': 'Про які країни чи міста йдеться в цьому мемі?', 'ground-truth-answer': 'Франція', 'answer': 'У цьому мемі зображені країни, які не зображені в тексті, тому я не можу відповісти на це запитання.', 'metric': {'precision': 0.47515779733657837, 'recall': 0.5983523726463318, 'f1': 0.5296862721443176}},\n",
       "       {'question': 'Про яку подію йдеться у цьому мемі?', 'ground-truth-answer': 'Росія обстрілює цивільну інфраструктуру в Україні, викликаючи відключення світла', 'answer': '8-й день народження.', 'metric': {'precision': 0.5569350719451904, 'recall': 0.5079895853996277, 'f1': 0.5313374400138855}},\n",
       "       {'question': 'Про які країни чи міста йдеться в цьому мемі?', 'ground-truth-answer': 'Орськ', 'answer': 'Кілька країни, в яких зображено зображення, — це Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна, Україна', 'metric': {'precision': 0.4733380973339081, 'recall': 0.6075618863105774, 'f1': 0.532116174697876}},\n",
       "       {'question': 'Про яку подію йдеться у цьому мемі?', 'ground-truth-answer': 'Ukraine celebrates Vyshyvanka Day', 'answer': 'На зображенні зображено подію, яка не виставлена в тексті, тому я не можу відповісти на це запитання.', 'metric': {'precision': 0.5228078365325928, 'recall': 0.5523869395256042, 'f1': 0.5371904969215393}}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_10_indices = np.argsort(f1_scores)[:10]\n",
    "np.array(results)[worst_10_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5852968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_filename = file_name.split('.')[0] + 'with_metrics.' + file_name.split('.')[1]\n",
    "\n",
    "with open(result_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7af22a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
